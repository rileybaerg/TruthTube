{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rileybaerg/TruthTube/blob/main/TruthTubePracticumColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCoM7T-guu3q"
   },
   "source": [
    "# TruthTube Project Practicum\n",
    "Riley, Jiyoon, Keyan, Mustafa\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ6T9ZBQXMM9"
   },
   "source": [
    "## Problem\n",
    "\n",
    "We are concerned with the spread of health misinformation on YouTube, especially within YouTube shorts where the duration of a video is less than 60 seconds and spreads at a fast pace. We wish to examine how misinformative videos influence viewers, particularly focusing on the topic of Nutrition.\n",
    "\n",
    "RQ: How does the interaction between the content of a nutritional health video impact its popularity and uptake of content by viewers when it is informative versus misinformative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxeIfZzdm_oB"
   },
   "source": [
    "## Method\n",
    "\n",
    "We decide to analyze comments from YouTube Shorts videos surrounding nutritional health topics. Text data from comments will help us understand the interactions between a video and its viewers. We select misinformative health channels and informative health channels. We select 3 YouTube channels for each category, processing data from a total of 6 channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwE7kr8hWAHu"
   },
   "source": [
    "### Criteria\n",
    "In order to define informative health content, we follow\n",
    "https://www.ncbi.nlm.nih.gov/books/NBK225306/, where they indicate that \"the registered dietitian is the single identifiable group of healthcare professionals with the standardized education, clinical training, continuing education, and national credentialing requirements necessary to provide nutrition therapy.\"\n",
    "\n",
    "We noticed that the channel owner YouTube Shorts regarding nutritional health. Therefore, we set the criteria of a channel owner as having the qualifications of:\n",
    "\n",
    "* A Registered Dietitian (RD or RDN)\n",
    "* A person whose claims doesn't go against current nutrition guidelines provided by websites listed in https://openoregon.pressbooks.pub/nutritionscience/chapter/2e-who-can-you-trust/\n",
    "* Someone who does not push an agenda or product available after purpose (those leveraging their health education into a health-business related career); promoting self-interests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gO14Wfl7WjOX"
   },
   "source": [
    "## Quantiative\n",
    "### Channel Information and Uploads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uuH8EJVOKNL3"
   },
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "\n",
    "api_key = \"AIzaSyBHMgFLFQX2mvLQqD4do9xrTv07hjPPX0U\"\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "youtube = build(\n",
    "    api_service_name, api_version, developerKey=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vsf41l3_iTul"
   },
   "source": [
    "Using the YouTube Data API, we first collect summary information for YouTube channels. We use the YouTube channel's ID to identify each YouTube channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HOlrFnmGWi2V"
   },
   "outputs": [],
   "source": [
    "def get_channel_info(userid):\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=userid\n",
    "    )\n",
    "    response = request.execute()\n",
    "    item = response['items'][0]\n",
    "    # Your solution\n",
    "    return {\n",
    "        'channelName': item['snippet']['title'],\n",
    "        'channelStartDate': item['snippet']['publishedAt'],\n",
    "        'subscribers': item['statistics']['subscriberCount'],\n",
    "        'viewCount': item['statistics']['viewCount'],\n",
    "        'videoCount': item['statistics']['videoCount'],\n",
    "        'uploadsPlaylist': item['contentDetails']['relatedPlaylists']['uploads']\n",
    "    }\n",
    "def get_video_data(video_ids):\n",
    "    video_data = []\n",
    "    for i in range (0, len(video_ids), 50): # performs requests in batches to avoid rate-limiting\n",
    "        request = youtube.videos().list(\n",
    "            part='snippet,contentDetails,statistics',\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute() #record response\n",
    "\n",
    "        for item in response['items']:\n",
    "            relevant_stats = {\n",
    "                'snippet': ['title', 'description', 'tags', 'publishedAt'],\n",
    "                'statistics': ['viewCount', 'likeCount', 'commentCount'],\n",
    "                'contentDetails': ['duration', 'definition', 'caption']\n",
    "            } #collects information that we care about... check documentation to choose information\n",
    "\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = item['id']\n",
    "\n",
    "            for cat in relevant_stats.keys():\n",
    "                for stat in relevant_stats[cat]:\n",
    "                    try:\n",
    "                        video_info[stat] = item[cat][stat]\n",
    "                    except:\n",
    "                        video_info[stat] = None\n",
    "\n",
    "            video_data.append(video_info)\n",
    "    video_data\n",
    "    return pd.DataFrame(video_data)\n",
    "\n",
    "# Define any helper functions here\n",
    "def get_video_ids(playlistID):\n",
    "    request = youtube.playlistItems().list(\n",
    "        part='snippet,contentDetails',\n",
    "        playlistId = playlistID,\n",
    "        maxResults=50\n",
    "    )\n",
    "\n",
    "    response = request.execute()\n",
    "\n",
    "    video_ids = []\n",
    "    video_ids.extend([item['contentDetails']['videoId'] for item in response['items']])\n",
    "\n",
    "    next_page = response.get('nextPageToken')\n",
    "\n",
    "    while next_page is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part='snippet,contentDetails',\n",
    "            playlistId = playlistID,\n",
    "            maxResults = 50,\n",
    "            pageToken = next_page\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        video_ids.extend([item['contentDetails']['videoId'] for item in response['items']])\n",
    "        next_page = response.get('nextPageToken')\n",
    "\n",
    "    return video_ids\n",
    "\n",
    "def get_channel_data(userid):\n",
    "    channel_info = get_channel_info(userid)\n",
    "    shorts_playlistid = \"UUSH\" + userid[2:]\n",
    "\n",
    "    video_ids = get_video_ids(shorts_playlistid)\n",
    "    upload_data = get_video_data(video_ids)\n",
    "    upload_data.insert(0, 'channelName', channel_info['channelName'])\n",
    "\n",
    "    return channel_info, upload_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n07RpCcxmOoW"
   },
   "source": [
    "Based on the criteria, we identify misinformative and informative youtube channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "goLPwOlXKhEQ"
   },
   "outputs": [],
   "source": [
    "# Misinformative youtube channels\n",
    "mis1_id = \"UC3w193M5tYPJqF0Hi-7U-2g\"\n",
    "mis2_id = \"UC5apkKkeZQXRSDbqSalG8CQ\"\n",
    "mis3_id = \"UCgBg0LcHfnJDPmFTTf677Pw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jt7uQFmnKxyl"
   },
   "outputs": [],
   "source": [
    "# Informative channel ids\n",
    "inf1_id = \"UCcffZfMDLakH-hs89uSKxQg\"\n",
    "inf2_id = \"UCKLz-9xkpPNjK26PqbjHn7Q\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zH-F_5T8rCVw"
   },
   "source": [
    "Then we pull data about these channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "POEF-FklIcIv"
   },
   "outputs": [],
   "source": [
    "mis1_info, mis1_uploads = get_channel_data(mis1_id)\n",
    "mis2_info, mis2_uploads = get_channel_data(mis2_id)\n",
    "mis3_info, mis3_uploads = get_channel_data(mis3_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7HXVpTe0K576"
   },
   "outputs": [],
   "source": [
    "inf1_info, inf1_uploads = get_channel_data(inf1_id)\n",
    "inf2_info, inf2_uploads = get_channel_data(inf2_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgOmxoraSYrl"
   },
   "source": [
    "We add boolean values to each group, adding a column named is_informative. (informative videos: 1, misinformative videos: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GDBv8bEMSYLj"
   },
   "outputs": [],
   "source": [
    "mis1_uploads['is_informative'] = int(False)\n",
    "mis2_uploads['is_informative'] = int(False)\n",
    "mis3_uploads['is_informative'] = int(False)\n",
    "inf1_uploads['is_informative'] = int(True)\n",
    "inf2_uploads['is_informative'] = int(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iFRfYp0TBRu"
   },
   "source": [
    "We have 3 dataframes that contain upload information for each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Wa3J_JooS4c5"
   },
   "outputs": [],
   "source": [
    "misinfo_df = pd.concat([mis1_uploads, mis2_uploads, mis3_uploads], axis=0)\n",
    "info_df = pd.concat([inf1_uploads, inf2_uploads], axis=0)\n",
    "youtube_df = pd.concat([misinfo_df, info_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelName</th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>duration</th>\n",
       "      <th>definition</th>\n",
       "      <th>caption</th>\n",
       "      <th>is_informative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Eric Berg DC</td>\n",
       "      <td>zqdxQWTdIM4</td>\n",
       "      <td>The Absolute Best Natural Vitamin for Arthriti...</td>\n",
       "      <td>Dr. Eric Berg DC Bio:\\nDr. Berg, age 58, is a ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-11T01:32:38Z</td>\n",
       "      <td>618949</td>\n",
       "      <td>52821</td>\n",
       "      <td>972</td>\n",
       "      <td>PT1M</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Eric Berg DC</td>\n",
       "      <td>aYV9EWaiz_Y</td>\n",
       "      <td>3 Tips to Lose Weight While Sleeping #health #...</td>\n",
       "      <td>Dr. Eric Berg DC Bio:\\nDr. Berg, age 58, is a ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-07T21:30:23Z</td>\n",
       "      <td>509411</td>\n",
       "      <td>34856</td>\n",
       "      <td>451</td>\n",
       "      <td>PT1M</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Eric Berg DC</td>\n",
       "      <td>G4guVvCYAEA</td>\n",
       "      <td>Discover the biggest culprit behind inflammati...</td>\n",
       "      <td>Dr. Eric Berg DC Bio:\\nDr. Berg, age 58, is a ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-07T00:00:12Z</td>\n",
       "      <td>164654</td>\n",
       "      <td>11340</td>\n",
       "      <td>212</td>\n",
       "      <td>PT53S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Eric Berg DC</td>\n",
       "      <td>u0-U3-f4VHM</td>\n",
       "      <td>Explore the health advantages provided by ging...</td>\n",
       "      <td>Dr. Eric Berg DC Bio:\\nDr. Berg, age 58, is a ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-06T20:14:30Z</td>\n",
       "      <td>115410</td>\n",
       "      <td>9907</td>\n",
       "      <td>242</td>\n",
       "      <td>PT40S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. Eric Berg DC</td>\n",
       "      <td>llDg68l626M</td>\n",
       "      <td>Craving some KFC? 🍗🍟 Before your next run, dis...</td>\n",
       "      <td>Dr. Eric Berg DC Bio:\\nDr. Berg, age 58, is a ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-05T19:31:40Z</td>\n",
       "      <td>352476</td>\n",
       "      <td>22457</td>\n",
       "      <td>1082</td>\n",
       "      <td>PT59S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>Paul Saladino MD</td>\n",
       "      <td>e-KTjQyZNvQ</td>\n",
       "      <td>An animal-based diet is optimal for humans</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2022-04-16T21:03:26Z</td>\n",
       "      <td>54535</td>\n",
       "      <td>1617</td>\n",
       "      <td>50</td>\n",
       "      <td>PT16S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Paul Saladino MD</td>\n",
       "      <td>O2Wn76_EHnM</td>\n",
       "      <td>Heal with an animal-based diet!</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2022-04-16T20:58:14Z</td>\n",
       "      <td>55609</td>\n",
       "      <td>2921</td>\n",
       "      <td>107</td>\n",
       "      <td>PT55S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>Paul Saladino MD</td>\n",
       "      <td>AuBzPFyO-Ck</td>\n",
       "      <td>My animal-based breakfast</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2022-04-16T20:47:07Z</td>\n",
       "      <td>354896</td>\n",
       "      <td>8912</td>\n",
       "      <td>635</td>\n",
       "      <td>PT47S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>Paul Saladino MD</td>\n",
       "      <td>ne-0X9uj2ew</td>\n",
       "      <td>Animal-based day of eating!</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2022-04-16T19:49:01Z</td>\n",
       "      <td>4388840</td>\n",
       "      <td>124123</td>\n",
       "      <td>8466</td>\n",
       "      <td>PT55S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>Paul Saladino MD</td>\n",
       "      <td>w5xl6CEnAbQ</td>\n",
       "      <td>Plants Have Their Own Agenda (Power Project Po...</td>\n",
       "      <td>PATREON: https://www.patreon.com/paulsaladinom...</td>\n",
       "      <td>[medicine, carnivore diet, keto diet, keto, li...</td>\n",
       "      <td>2019-03-09T21:26:37Z</td>\n",
       "      <td>59205</td>\n",
       "      <td>1332</td>\n",
       "      <td>133</td>\n",
       "      <td>PT59S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1171 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          channelName     video_id  \\\n",
       "0    Dr. Eric Berg DC  zqdxQWTdIM4   \n",
       "1    Dr. Eric Berg DC  aYV9EWaiz_Y   \n",
       "2    Dr. Eric Berg DC  G4guVvCYAEA   \n",
       "3    Dr. Eric Berg DC  u0-U3-f4VHM   \n",
       "4    Dr. Eric Berg DC  llDg68l626M   \n",
       "..                ...          ...   \n",
       "598  Paul Saladino MD  e-KTjQyZNvQ   \n",
       "599  Paul Saladino MD  O2Wn76_EHnM   \n",
       "600  Paul Saladino MD  AuBzPFyO-Ck   \n",
       "601  Paul Saladino MD  ne-0X9uj2ew   \n",
       "602  Paul Saladino MD  w5xl6CEnAbQ   \n",
       "\n",
       "                                                 title  \\\n",
       "0    The Absolute Best Natural Vitamin for Arthriti...   \n",
       "1    3 Tips to Lose Weight While Sleeping #health #...   \n",
       "2    Discover the biggest culprit behind inflammati...   \n",
       "3    Explore the health advantages provided by ging...   \n",
       "4    Craving some KFC? 🍗🍟 Before your next run, dis...   \n",
       "..                                                 ...   \n",
       "598         An animal-based diet is optimal for humans   \n",
       "599                    Heal with an animal-based diet!   \n",
       "600                          My animal-based breakfast   \n",
       "601                        Animal-based day of eating!   \n",
       "602  Plants Have Their Own Agenda (Power Project Po...   \n",
       "\n",
       "                                           description  \\\n",
       "0    Dr. Eric Berg DC Bio:\\nDr. Berg, age 58, is a ...   \n",
       "1    Dr. Eric Berg DC Bio:\\nDr. Berg, age 58, is a ...   \n",
       "2    Dr. Eric Berg DC Bio:\\nDr. Berg, age 58, is a ...   \n",
       "3    Dr. Eric Berg DC Bio:\\nDr. Berg, age 58, is a ...   \n",
       "4    Dr. Eric Berg DC Bio:\\nDr. Berg, age 58, is a ...   \n",
       "..                                                 ...   \n",
       "598                                                      \n",
       "599                                                      \n",
       "600                                                      \n",
       "601                                                      \n",
       "602  PATREON: https://www.patreon.com/paulsaladinom...   \n",
       "\n",
       "                                                  tags           publishedAt  \\\n",
       "0                                                 None  2024-03-11T01:32:38Z   \n",
       "1                                                 None  2024-03-07T21:30:23Z   \n",
       "2                                                 None  2024-03-07T00:00:12Z   \n",
       "3                                                 None  2024-03-06T20:14:30Z   \n",
       "4                                                 None  2024-03-05T19:31:40Z   \n",
       "..                                                 ...                   ...   \n",
       "598                                               None  2022-04-16T21:03:26Z   \n",
       "599                                               None  2022-04-16T20:58:14Z   \n",
       "600                                               None  2022-04-16T20:47:07Z   \n",
       "601                                               None  2022-04-16T19:49:01Z   \n",
       "602  [medicine, carnivore diet, keto diet, keto, li...  2019-03-09T21:26:37Z   \n",
       "\n",
       "    viewCount likeCount commentCount duration definition caption  \\\n",
       "0      618949     52821          972     PT1M         hd   false   \n",
       "1      509411     34856          451     PT1M         hd   false   \n",
       "2      164654     11340          212    PT53S         hd   false   \n",
       "3      115410      9907          242    PT40S         hd   false   \n",
       "4      352476     22457         1082    PT59S         hd   false   \n",
       "..        ...       ...          ...      ...        ...     ...   \n",
       "598     54535      1617           50    PT16S         hd   false   \n",
       "599     55609      2921          107    PT55S         hd   false   \n",
       "600    354896      8912          635    PT47S         hd   false   \n",
       "601   4388840    124123         8466    PT55S         hd   false   \n",
       "602     59205      1332          133    PT59S         hd   false   \n",
       "\n",
       "     is_informative  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "..              ...  \n",
       "598               0  \n",
       "599               0  \n",
       "600               0  \n",
       "601               0  \n",
       "602               0  \n",
       "\n",
       "[1171 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misinfo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EEN_-A3x_0R"
   },
   "source": [
    "#### Analyzing channel general information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wm0UMkev2oo7"
   },
   "source": [
    "Calculate the average view count, like cout, and comment count of all channels to have a general idea of the size of the channel and its interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "GW6vy8U91Qu8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channelName       object\n",
      "video_id          object\n",
      "title             object\n",
      "description       object\n",
      "tags              object\n",
      "publishedAt       object\n",
      "viewCount         object\n",
      "likeCount         object\n",
      "commentCount      object\n",
      "duration          object\n",
      "definition        object\n",
      "caption           object\n",
      "is_informative     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#check data type of the columns analyzing\n",
    "print(youtube_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "gT2ngxv80n7b"
   },
   "outputs": [],
   "source": [
    "#convert data type from to integer if it is not already for analysis\n",
    "youtube_df['viewCount'] = pd.to_numeric(youtube_df['viewCount'], errors='coerce', downcast='integer')\n",
    "youtube_df['commentCount'] = pd.to_numeric(youtube_df['commentCount'], errors='coerce', downcast='integer')\n",
    "youtube_df['likeCount'] = pd.to_numeric(youtube_df['likeCount'], errors='coerce', downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "EqiqAIDox-yk",
    "outputId": "825dbd1b-f739-49b7-a27e-453b14644e69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Average View Count</th>\n",
       "      <th>Average Comment Count</th>\n",
       "      <th>Average Like Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbey Sharp</td>\n",
       "      <td>243457.11</td>\n",
       "      <td>290.50</td>\n",
       "      <td>12350.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Eric Berg DC</td>\n",
       "      <td>247269.38</td>\n",
       "      <td>400.86</td>\n",
       "      <td>14232.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nutrition By Kylie</td>\n",
       "      <td>1989573.26</td>\n",
       "      <td>589.78</td>\n",
       "      <td>125964.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paul Saladino MD</td>\n",
       "      <td>245392.89</td>\n",
       "      <td>604.73</td>\n",
       "      <td>9945.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shawn Baker MD</td>\n",
       "      <td>31796.15</td>\n",
       "      <td>109.66</td>\n",
       "      <td>1956.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Channel Name  Average View Count  Average Comment Count  \\\n",
       "0         Abbey Sharp           243457.11                 290.50   \n",
       "1    Dr. Eric Berg DC           247269.38                 400.86   \n",
       "2  Nutrition By Kylie          1989573.26                 589.78   \n",
       "3    Paul Saladino MD           245392.89                 604.73   \n",
       "4      Shawn Baker MD            31796.15                 109.66   \n",
       "\n",
       "   Average Like Count  \n",
       "0            12350.39  \n",
       "1            14232.49  \n",
       "2           125964.16  \n",
       "3             9945.75  \n",
       "4             1956.15  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average view count, comment count, and like count for each channel\n",
    "average_metrics = youtube_df.groupby('channelName').agg({\n",
    "    'viewCount': 'mean',\n",
    "    'commentCount': 'mean',\n",
    "    'likeCount': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "average_metrics.columns = ['Channel Name', 'Average View Count', 'Average Comment Count', 'Average Like Count']\n",
    "\n",
    "#change the avaerge number format to decimal\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# Display the table with average metrics for each channel\n",
    "average_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO-KrIY9Mem1"
   },
   "source": [
    "### Retrieving Comments Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting shorts comments for our selected channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified function to get 100 comments per video\n",
    "def get_comments_in_videos(video_ids):\n",
    "    all_comments = []\n",
    "\n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            comments_in_video = []\n",
    "\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=100  # Adjust this number as per your requirements\n",
    "            )\n",
    "\n",
    "            while request:\n",
    "                response = request.execute()\n",
    "\n",
    "                for comment in response['items']:\n",
    "                    comments_in_video.append(comment['snippet']['topLevelComment']['snippet']['textOriginal'])\n",
    "\n",
    "                request = youtube.commentThreads().list_next(request, response)\n",
    "\n",
    "            comments_in_video_info = {'video_id': video_id, 'comments': comments_in_video}\n",
    "            all_comments.append(comments_in_video_info)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Could not get comments for video {video_id}: {str(e)}')\n",
    "\n",
    "    return pd.DataFrame(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get comments for video B1iDumoCaOI: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=B1iDumoCaOI&maxResults=100&key=AIzaSyBHMgFLFQX2mvLQqD4do9xrTv07hjPPX0U&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.', 'domain': 'youtube.commentThread', 'reason': 'commentsDisabled', 'location': 'videoId', 'locationType': 'parameter'}]\">\n",
      "Could not get comments for video GWheYMsm8QY: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=GWheYMsm8QY&maxResults=100&key=AIzaSyBHMgFLFQX2mvLQqD4do9xrTv07hjPPX0U&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.', 'domain': 'youtube.commentThread', 'reason': 'commentsDisabled', 'location': 'videoId', 'locationType': 'parameter'}]\">\n",
      "Could not get comments for video GMGJJjf3wjk: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=GMGJJjf3wjk&maxResults=100&key=AIzaSyBHMgFLFQX2mvLQqD4do9xrTv07hjPPX0U&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.', 'domain': 'youtube.commentThread', 'reason': 'commentsDisabled', 'location': 'videoId', 'locationType': 'parameter'}]\">\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mis_comments\u001b[38;5;241m=\u001b[39m get_comments_in_videos(misinfo_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m, in \u001b[0;36mget_comments_in_videos\u001b[0;34m(video_ids)\u001b[0m\n\u001b[1;32m      9\u001b[0m request \u001b[38;5;241m=\u001b[39m youtube\u001b[38;5;241m.\u001b[39mcommentThreads()\u001b[38;5;241m.\u001b[39mlist(\n\u001b[1;32m     10\u001b[0m     part\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnippet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     videoId\u001b[38;5;241m=\u001b[39mvideo_id,\n\u001b[1;32m     12\u001b[0m     maxResults\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m  \u001b[38;5;66;03m# Adjust this number as per your requirements\u001b[39;00m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m request:\n\u001b[0;32m---> 16\u001b[0m     response \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mexecute()\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     19\u001b[0m         comments_in_video\u001b[38;5;241m.\u001b[39mappend(comment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnippet\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopLevelComment\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnippet\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtextOriginal\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/googleapiclient/http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody))\n\u001b[1;32m    922\u001b[0m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[0;32m--> 923\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m _retry_request(\n\u001b[1;32m    924\u001b[0m     http,\n\u001b[1;32m    925\u001b[0m     num_retries,\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sleep,\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rand,\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri),\n\u001b[1;32m    930\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod),\n\u001b[1;32m    931\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    932\u001b[0m     headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    933\u001b[0m )\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_callbacks:\n\u001b[1;32m    936\u001b[0m     callback(resp)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/googleapiclient/http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     resp, content \u001b[38;5;241m=\u001b[39m http\u001b[38;5;241m.\u001b[39mrequest(uri, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _ssl_SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_error:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httplib2/__init__.py:1724\u001b[0m, in \u001b[0;36mHttp.request\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m   1722\u001b[0m             content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1724\u001b[0m             (response, content) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1725\u001b[0m                 conn, authority, uri, request_uri, method, body, headers, redirections, cachekey,\n\u001b[1;32m   1726\u001b[0m             )\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1728\u001b[0m     is_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(e, socket\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httplib2/__init__.py:1444\u001b[0m, in \u001b[0;36mHttp._request\u001b[0;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth:\n\u001b[1;32m   1442\u001b[0m     auth\u001b[38;5;241m.\u001b[39mrequest(method, request_uri, headers, body)\n\u001b[0;32m-> 1444\u001b[0m (response, content) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn_request(conn, request_uri, method, body, headers)\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth:\n\u001b[1;32m   1447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m auth\u001b[38;5;241m.\u001b[39mresponse(response, body):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/httplib2/__init__.py:1396\u001b[0m, in \u001b[0;36mHttp._conn_request\u001b[0;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1395\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1396\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mBadStatusLine, http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mResponseNotReady):\n\u001b[1;32m   1398\u001b[0m     \u001b[38;5;66;03m# If we get a BadStatusLine on the first try then that means\u001b[39;00m\n\u001b[1;32m   1399\u001b[0m     \u001b[38;5;66;03m# the connection just went stale, so retry regardless of the\u001b[39;00m\n\u001b[1;32m   1400\u001b[0m     \u001b[38;5;66;03m# number of RETRIES set.\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m seen_bad_status_line \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/http/client.py:1386\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1385\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1386\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#comments for misinformative channels\n",
    "mis_comments= get_comments_in_videos(misinfo_df['video_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comments for informative channels\n",
    "info_comments= get_comments_in_videos(info_df['video_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMSVTr81vDjm"
   },
   "source": [
    "####  Data Cleaning and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiRwgIzEIjI7"
   },
   "source": [
    "Processing data using pandas\n",
    "(Code below uses arbitrary names and names need to be replaced accordingly when using)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_JSXHAt5rHA7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "9I4uskwVJFLB"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'name.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m name_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#replace name.csv with actual name of the csv file, relace name_df with a good naming for this df\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'name.csv'"
     ]
    }
   ],
   "source": [
    "name_df = pd.read_csv('name.csv', delimiter=\",\") #replace name.csv with actual name of the csv file, relace name_df with a good naming for this df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PalcRkgvJbx7"
   },
   "source": [
    "Change all comments to lower cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LRRfJPlJhdD"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'comments'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'comments'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mname_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcomments\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;66;03m#if the name of the column comments are in is different, address accoridngly\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'comments'"
     ]
    }
   ],
   "source": [
    "name_df['comments'].str.lower() #if the name of the column comments are in is different, address accoridngly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEUg3ls7JnDe"
   },
   "source": [
    "Remove special characters and keep alphanumeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5uLBC1WJtjV"
   },
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'  # Keep alphanumeric characters and whitespace\n",
    "    return re.sub(pattern, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSi6st2bNiJ5"
   },
   "outputs": [],
   "source": [
    "# Apply the function to the 'comments' column, store cleaned comments in 'clean_comments'\n",
    "name_df['clean_comments'] = name_df['comments'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmovhnfBJ4Jd"
   },
   "outputs": [],
   "source": [
    "name_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbU8AFfpJ8Mw"
   },
   "source": [
    "Split comments into token using nltk library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JjETSrckJ7E9"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SIVQWkVyNu3d"
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzVZz9DjNyVw"
   },
   "outputs": [],
   "source": [
    "# Apply the function to the 'clean_comments' column, store tokenized comments in 'tokenized_comments'\n",
    "name_df['tokenized_comments']=name_df['clean_comments'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-5DInBgN1iw"
   },
   "outputs": [],
   "source": [
    "name_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoKhESfoFtPq"
   },
   "source": [
    "Removing stop words using NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4TmP7DnFs1a",
    "outputId": "06799b8a-87d5-4168-cf03-2d7252eb7e9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-F1r6XXXGZIo"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "  # Get the set of English stopwords from NLTK\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "    # Filter out stopwords from the list of tokens\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in english_stopwords]\n",
    "\n",
    "    return filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIgF5K7XG3a0"
   },
   "outputs": [],
   "source": [
    "# Apply remove_stopwords function to the 'tokenized_words' column\n",
    "name_df['filtered_words'] = name_df['tokenized_words'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condensed Comment Preprocessing Methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\baerg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\baerg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'comments'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'comments'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# apply function to comment dataframe (name for now, until official variable name is established)\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m name_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_comments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mname_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcomments\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mapply(clean_tokenize_text)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'comments'"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# download Natural Language Toolkit parameter learners and stopword removal resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# encompassing text cleaning and tokenizing function\n",
    "def clean_tokenize_text(text):\n",
    "  # convert text to all lowercase\n",
    "  text = text.lower()\n",
    "  # remove any special characters and ensure that only alphanumeric characters are kept\n",
    "  text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "  # tokenize the text\n",
    "  tokens = word_tokenize(text)\n",
    "  # stopword removal steps\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  tokens = [token for token in tokens if token not in stop_words]\n",
    "  return tokens\n",
    "\n",
    "# apply function to comment dataframe (name for now, until official variable name is established)\n",
    "name_df['clean_comments'] = name_df['comments'].str.lower().apply(clean_tokenize_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis and Visualization of Comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'comments'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'comments'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m blob\u001b[38;5;241m.\u001b[39msentiment\u001b[38;5;241m.\u001b[39mpolarity\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Apply the sentiment analysis function to current data frame\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m name_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mname_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcomments\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(calculate_sentiment_score)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Visualize the sentiment distribution using matplotlib\u001b[39;00m\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(name_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m], bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskyblue\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'comments'"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob #!pip install textblob ;)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sentiment score calcuation function utilizing textblob\n",
    "def calculate_sentiment_score(text):\n",
    "  blob = TextBlob(text)\n",
    "  return blob.sentiment.polarity\n",
    "\n",
    "# Apply the sentiment analysis function to current data frame\n",
    "name_df['sentiment_score'] = name_df['comments'].apply(calculate_sentiment_score)\n",
    "\n",
    "# Visualize the sentiment distribution using matplotlib\n",
    "plt.hist(name_df['sentiment_score'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Sentiment Distribution of Comments')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkYAsf6pKUnG"
   },
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vq9Dy8NdWmqZ"
   },
   "source": [
    "## Credits\n",
    "Credit listing of what each team member contributed to completing this part of the project.\n",
    "\n",
    "Riley\n",
    "*   Attended project check-ins and meetings to refine research question.\n",
    "*   Outlined groups Data Science process in attempt to solidify each steps contribution to addressing our research question.\n",
    "*   Contributed to writing YouTube Comment data analysis and visualization (calculate_sentiment_score)\n",
    "*   Assessed and contributed to YouTube Comment Preprocessing code (clean_tokenize_text)\n",
    "\n",
    "Jiyoon\n",
    "*   Attended project check-ins and meetings to refine research question\n",
    "*   Wrote problem, method, criteria sections\n",
    "*   Wrote code for receiving channel data\n",
    "*   Wrote code for creating uploads data (misinfo_df, info_df, youtube_df)\n",
    "\n",
    "Keyan\n",
    "*   Attended project check-ins and meetings to refine research question\n",
    "*   Wrote code for data cleaning and processing part\n",
    "*   Wrote code for general channel analysis (computing averages)\n",
    "\n",
    "Mustafa\n",
    "*   List item\n",
    "*   List item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMIEXpFJWyAI"
   },
   "source": [
    "## Processed data files\n",
    "Processed data files (in compressed form if large), preferably in CSV format. If it still does not fit, let us know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSpn8TDrIqm7"
   },
   "outputs": [],
   "source": [
    "youtube_df.to_csv('all_uploads.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
