{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Separate analysis for informative and misinformative transcripts\n",
    "informative_tokens = []\n",
    "for transcript in infotranscripts_df['clean_transcript']:\n",
    "  tokens = nltk.word_tokenize(transcript)\n",
    "  informative_tokens.extend(tokens)\n",
    "\n",
    "misinformative_tokens = []\n",
    "for transcript in mistranscripts_df['clean_transcript']:\n",
    "  tokens = nltk.word_tokenize(transcript)\n",
    "  misinformative_tokens.extend(tokens)\n",
    "\n",
    "# Generate n-grams for each group\n",
    "informative_bigrams = [' '.join(gram) for gram in ngrams(informative_tokens, 2)]\n",
    "informative_trigrams = [' '.join(gram) for gram in ngrams(informative_tokens, 3)]\n",
    "misinformative_bigrams = [' '.join(gram) for gram in ngrams(misinformative_tokens, 2)]\n",
    "misinformative_trigrams = [' '.join(gram) for gram in ngrams(misinformative_tokens, 3)]\n",
    "\n",
    "# Combine n-grams within each group\n",
    "informative_text_ngrams = informative_bigrams + informative_trigrams\n",
    "misinformative_text_ngrams = misinformative_bigrams + misinformative_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_ngrams = informative_text_ngrams + misinformative_text_ngrams\n",
    "ngram_freq = Counter(all_ngrams)\n",
    "ngram_freq\n",
    "# Create Word Cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(ngram_freq)\n",
    "\n",
    "# Plot Word Cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob \n",
    "def calculate_sentiment_score(text):\n",
    "  blob = TextBlob(text)\n",
    "  return blob.sentiment.polarity\n",
    "\n",
    "informative_sentiment_scores = []\n",
    "for ngram in informative_text_ngrams:\n",
    "  score = calculate_sentiment_score(ngram)\n",
    "  informative_sentiment_scores.append(score)\n",
    "\n",
    "informative_sentiment_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misinformative_sentiment_scores = []\n",
    "for ngram in misinformative_text_ngrams:\n",
    "  score = calculate_sentiment_score(ngram)\n",
    "  misinformative_sentiment_scores.append(score)\n",
    "misinformative_sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'misinformative_text_ngrams' and sentiment scores are in separate lists\n",
    "mis_ngrams_scores = list(zip(misinformative_text_ngrams, misinformative_sentiment_scores))\n",
    "# Create a DataFrame with columns 'ngram' and 'sentiment_score'\n",
    "mis_ngram_df = pd.DataFrame(mis_ngrams_scores, columns=['ngram', 'sentiment_score'])\n",
    "mis_ngram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_ngrams_scores = list(zip(informative_text_ngrams, informative_sentiment_scores))\n",
    "# Create a DataFrame with columns 'ngram' and 'sentiment_score'\n",
    "info_ngram_df = pd.DataFrame(info_ngrams_scores, columns=['ngram', 'sentiment_score'])\n",
    "info_ngram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Assuming you have DataFrames 'informative_df' and 'misinformative_df' with 'sentiment_score' columns\n",
    "sns.violinplot(x = \"category\", y = \"sentiment_score\", showmeans=True, data=pd.concat([info_ngram_df.assign(category='Informative'), mis_ngram_df.assign(category='Misinformative')], sort=False))\n",
    "plt.xlabel(\"N-gram Category\")\n",
    "plt.ylabel(\"Sentiment Score\")\n",
    "plt.title(\"Distribution of Sentiment Scores by N-gram Category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sentiment score threshold (adjust as needed)\n",
    "high_sentiment_threshold = 0.7\n",
    "\n",
    "# Filter informative n-grams with high sentiment scores\n",
    "informative_high_sentiment = info_ngram_df[info_ngram_df['sentiment_score'] >= high_sentiment_threshold]\n",
    "\n",
    "# Filter misinformative n-grams with high sentiment scores\n",
    "misinformative_high_sentiment = mis_ngram_df[mis_ngram_df['sentiment_score'] >= high_sentiment_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "informative_high_sentiment_sorted = informative_high_sentiment.sort_values(by='sentiment_score', ascending=False)\n",
    "misinformative_high_sentiment_sorted = misinformative_high_sentiment.sort_values(by='sentiment_score', ascending=False)\n",
    "informative_high_sentiment_sorted\n",
    "misinformative_high_sentiment_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wordcloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def generate_wordcloud(ngram_df, color):\n",
    "    # Combine all n-grams and their sentiment scores into a dictionary\n",
    "    sentimented_words = {row['ngram']: row['sentiment_score'] for index, row in ngram_df.iterrows()}\n",
    "    \n",
    "    # Create a WordCloud object with sentiment score as word weight\n",
    "    wordcloud = WordCloud(background_color='white').generate_from_frequencies(sentimented_words)\n",
    "    \n",
    "    # Display the WordCloud\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"High Sentiment N-grams - {color}\")\n",
    "    plt.show()\n",
    "\n",
    "# Generate WordClouds for informative and misinformative high-sentiment n-grams\n",
    "generate_wordcloud(informative_high_sentiment_sorted.copy(), 'Informative')\n",
    "generate_wordcloud(misinformative_high_sentiment_sorted.copy(), 'Misinformative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sentiment score threshold (adjust as needed)\n",
    "negative_sentiment_threshold = -0.3\n",
    "\n",
    "# Filter informative n-grams with low sentiment scores\n",
    "informative_low_sentiment = info_ngram_df[info_ngram_df['sentiment_score'] <= negative_sentiment_threshold]\n",
    "\n",
    "# Filter misinformative n-grams with low sentiment scores\n",
    "misinformative_low_sentiment = mis_ngram_df[mis_ngram_df['sentiment_score'] <= negative_sentiment_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "informative_low_sentiment_sorted = informative_low_sentiment.sort_values(by='sentiment_score', ascending=True)\n",
    "misinformative_low_sentiment_sorted = misinformative_low_sentiment.sort_values(by='sentiment_score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_low_wordcloud(ngram_df, color):\n",
    "    # Combine all n-grams and their sentiment scores into a dictionary\n",
    "    sentimented_words = {row['ngram']: row['sentiment_score'] for index, row in ngram_df.iterrows()}\n",
    "    \n",
    "    # Create a WordCloud object with sentiment score as word weight\n",
    "    wordcloud = WordCloud(background_color='white').generate_from_frequencies(sentimented_words)\n",
    "    \n",
    "    # Display the WordCloud\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Low Sentiment N-grams - {color}\")\n",
    "    plt.show()\n",
    "\n",
    "generate_low_wordcloud(informative_low_sentiment_sorted.copy(), 'Informative')\n",
    "generate_low_wordcloud(misinformative_low_sentiment_sorted.copy(), 'Misinformative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract n-grams and sentiment scores for informative and misinformative dataframes\n",
    "top_informative_ngrams = informative_high_sentiment_sorted.head(10)['ngram'].tolist()\n",
    "top_informative_scores = informative_high_sentiment_sorted.head(10)['sentiment_score'].tolist()\n",
    "top_misinformative_ngrams = misinformative_high_sentiment_sorted.head(10)['ngram'].tolist()\n",
    "top_misinformative_scores = misinformative_high_sentiment_sorted.head(10)['sentiment_score'].tolist()\n",
    "top_informative_ngrams, top_misinformative_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_informative_ngrams = informative_low_sentiment_sorted.head(10)['ngram'].tolist()\n",
    "worst_informative_scores = informative_low_sentiment_sorted.head(10)['sentiment_score'].tolist()\n",
    "worst_misinformative_ngrams = misinformative_low_sentiment_sorted.head(10)['ngram'].tolist()\n",
    "worst_misinformative_scores = misinformative_low_sentiment_sorted.head(10)['sentiment_score'].tolist()\n",
    "worst_informative_ngrams, worst_misinformative_ngrams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
